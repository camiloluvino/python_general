{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraer tablas de PDFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versión Victor con 1 pdf excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerias\n",
    "from tabula import read_pdf\n",
    "#no etniendo...dbería importar tabula y con ello la funcíon, no eitneod por qué import + funcion\n",
    "import pandas as pd\n",
    "\n",
    "# leer pdf \n",
    "doc = read_pdf(\"fuentes de datos/extrae pdf/FMCA_17412886-3_202207_U_.pdf\", pages = \"all\")\n",
    "\n",
    "# devuelve una lista, que la llamamos \"doc\" que contiene el número de dataframes de acuerdo a las tablas que encontró.abs(x)\n",
    "print(\"tipo de objeto:\",type(doc))\n",
    "print(\"número de elementos:\",len(doc))\n",
    "#comentario: interesante que le pueda poner antes como el texto que define lo que aparecerá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un archivo llamado \"pdf.xlsx\"\n",
    "writer = pd.ExcelWriter(\"pdf.xlsx\")\n",
    "# la idea es guardar cada tabla en una hoja aparte dentro del mismo excel\n",
    "\n",
    "doc[0].to_excel(writer, sheet_name = \"tabla 1\")\n",
    "doc[1].to_excel(writer, sheet_name = \"tabla 2\")\n",
    "doc[2].to_excel(writer, sheet_name = \"tabla 3\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos lo mismo que el anterior de modo iterativo en vez de definir cada dataframe.\n",
    "\n",
    "writer = pd.ExcelWriter(\"pdf1.xlsx\")\n",
    "i=1\n",
    "for tabla in doc:\n",
    "   tabla.to_excel(writer, sheet_name = \"tabla\"+str(i))\n",
    "   i = i+1\n",
    "    \n",
    "writer.save()    \n",
    "\n",
    "#%%\n",
    "# un paréntesis, para concatenar dos o más strings, sólo basta sumarlos \n",
    "string1 = \"tabla\"\n",
    "string2 = \"2\"\n",
    "string = string1 +\"-\" +string2 \n",
    "print(string)\n",
    "\n",
    "#%%\n",
    "#importamos la libreria glob\n",
    "import glob\n",
    "\n",
    "path = r\"C:\\Users\\redk8\\Documents\\Proyectos en Python\\python_general\\fuentes de datos\\fondos mutuos\\*.pdf\"\n",
    "files = glob.glob(path)\n",
    "print(files)\n",
    "\n",
    "#la libreria tiene una funcion que permite encontrar archivos con algún patrón, en este caso los archivos pdf que están en la carpeta \"ejemplos_pdf\"\n",
    "archivos = glob.glob(\"ejemplos_pdf/*.pdf\")\n",
    "\n",
    "#la funcion devuelve una lista que la llamamos \"archivos\"\n",
    "\n",
    "doc = read_pdf(archivos[0], pages = \"all\")\n",
    "\n",
    "#%%\n",
    "# todos las tablas de la lista la guardamos de forma iterativa en un solo dataframe\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for page in doc:\n",
    "    df= pd.concat([df,page])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versión Chat GPT con varios excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabula import read_pdf\n",
    "\n",
    "def process_pdfs(pdf_files, excel_file):\n",
    "    # Create the ExcelWriter object\n",
    "    writer = pd.ExcelWriter(excel_file)\n",
    "    # Iterate through the list of PDF files\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        # Read the PDF and extract the tables\n",
    "        doc = read_pdf(pdf_file, pages = \"all\")\n",
    "        # Iterate through the list of tables\n",
    "        for j, df in enumerate(doc):\n",
    "            # Write each table to a different sheet in the Excel file\n",
    "            df.to_excel(writer, sheet_name = f\"tabla {i+1}_{j+1}\")\n",
    "    # Save the Excel file\n",
    "    writer.save()\n",
    "\n",
    "\n",
    "pdf_files = [\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202207_U_.pdf',\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202208_U_.pdf',\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202209_U_.pdf',\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202210_U_.pdf',\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202211_U_.pdf',\n",
    "    'C:\\\\Users\\\\redk8\\\\Documents\\\\Proyectos en Python\\\\python_general\\\\fuentes de datos\\\\extrae pdf\\\\FMCA_17412886-3_202212_U_.pdf'\n",
    "]\n",
    "\n",
    "process_pdfs(pdf_files, \"resultados/pdfs.xlsx\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraer texto de pdf (antiguo intento) no funciona con GHAT GPT me manda una función antigua y no actualiza bien cuando le pido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._reader.PdfReader object at 0x000001BF571330A0>\n"
     ]
    }
   ],
   "source": [
    "# importando PyPDF2\n",
    "import PyPDF2\n",
    "\n",
    "# abriendo el pdf\n",
    "pdf_file = open(\"fuentes de datos/extrae pdf/Brown - 2021 - En las ruinas del neoliberalismo el ascenso de la.pdf\", 'rb')\n",
    "pdf_extracto = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# iterando sobre las páginas del pdf\n",
    "for page in range(pdf_reader.numPages):\n",
    "    # extraer el texto de la página\n",
    "    text = pdf_reader.getPage(page).extractText()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    " \n",
    "def pdf_to_text(input_file,output):\n",
    "    i_f = open(input_file,'rb')\n",
    "    resMgr = PDFResourceManager()\n",
    "    retData = io.StringIO()\n",
    "    TxtConverter = TextConverter(resMgr,retData, laparams= LAParams())\n",
    "    interpreter = PDFPageInterpreter(resMgr,TxtConverter)\n",
    "    for page in PDFPage.get_pages(i_f):\n",
    "        interpreter.process_page(page)\n",
    " \n",
    "    txt = retData.getvalue()\n",
    "    print(txt)\n",
    "    with open(output,'w') as of:\n",
    "        of.write(txt)\n",
    " \n",
    "input_pdf = 'fuentes de datos/extrae pdf/Brown - 2021 - En las ruinas del neoliberalismo el ascenso de la.pdf'\n",
    "output_txt = 'brown.txt'\n",
    "pdf_to_text(input_pdf,output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "\n",
    "def pdf_to_text(input_file,output):\n",
    "    i_f = open(input_file,'rb')\n",
    "    resMgr = PDFResourceManager()\n",
    "    retData = io.StringIO()\n",
    "    TxtConverter = TextConverter(resMgr,retData, laparams= LAParams())\n",
    "    interpreter = PDFPageInterpreter(resMgr,TxtConverter)\n",
    "    for page in PDFPage.get_pages(i_f):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    txt = retData.getvalue()\n",
    "    print(txt)\n",
    "    with open(output,'w', encoding='utf-8') as of:\n",
    "        of.write(txt)\n",
    "\n",
    "input_pdf = 'fuentes de datos/extrae pdf/Brown - 2021 - En las ruinas del neoliberalismo el ascenso de la.pdf'\n",
    "output_txt = 'brown.txt'\n",
    "pdf_to_text(input_pdf,output_txt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fafc17c292403ba5b69e6ded93a13b0db856f90800c6ea582070588e41442cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
